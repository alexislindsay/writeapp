# LLM Provider Configuration
# Choose between 'ollama' (local) or 'together' (hosted)
LLM_PROVIDER=ollama

# Ollama Configuration (for local open-source LLM)
# Install Ollama from https://ollama.ai
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# Together AI Configuration (for hosted open-source LLM)
# Get API key from https://api.together.xyz
# TOGETHER_API_KEY=your_api_key_here
